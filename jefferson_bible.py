# -*- coding: utf-8 -*-
"""jefferson_bible.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cHyPCuzJADB4FEuUnZi1GhIBoCzcrBaT
"""

from bs4 import BeautifulSoup
import requests
import re
import json
from google.colab import drive

# ✅ Mount Google Drive
drive.mount('/content/drive')

# ✅ Target folder in your Drive
save_path = "/content/drive/MyDrive/bens_bible/jefferson_verses.json"

# ✅ Pages to scrape
pages = [15, 30, 45, 60, 75, 82]
base_url = "https://thejeffersonbible.com/index.php/tot{}"

all_verses = []

def clean_and_expand(raw):
    """Convert a raw opentjblink string into a clean list of verses."""
    verses = []
    parts = [p.strip() for p in raw.split(";") if p.strip()]
    for part in parts:
        part = part.replace("%20", " ").strip()
        if "," in part:
            book = part.split()[0].capitalize()
            chapter = part.split()[1].split(":")[0]
            refs = part.split()[1].split(":")[1].split(",")
            for r in refs:
                r = r.strip()
                if ":" in r:
                    verses.append(f"{book} {r}")
                else:
                    verses.append(f"{book} {chapter}:{r}")
        else:
            tokens = part.split()
            tokens[0] = tokens[0].capitalize()
            verses.append(" ".join(tokens))
    return verses

# ✅ Loop through all pages
for page in pages:
    url = base_url.format(page)
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")

    for a in soup.find_all("a", href=True):
        if "javascript:opentjblink" in a["href"]:
            match = re.search(r"opentjblink\('([^']+)'\)", a["href"])
            if match:
                all_verses.extend(clean_and_expand(match.group(1)))

# ✅ Save as JSON in your Google Drive
with open(save_path, "w", encoding="utf-8") as f:
    json.dump(all_verses, f, indent=2)

print(f"✅ Saved {len(all_verses)} verses to {save_path}")

import json
import requests
from collections import defaultdict
import re

# ✅ Paths
json_path = "/content/drive/MyDrive/bens_bible/jefferson_verses.json"
output_path = "/content/drive/MyDrive/bens_bible/jefferson_bible_web_offline.txt"

# ✅ Normalize book names
BOOK_MAP = {
    "Mathew": "Matthew",
    "Matthew": "Matthew",
    "Mark": "Mark",
    "Luke": "Luke",
    "John": "John"
}

# ✅ Load Jefferson references
with open(json_path, "r", encoding="utf-8") as f:
    jeff_refs = json.load(f)
print(f"Loaded {len(jeff_refs)} Jefferson references")

# ✅ Download and parse TehShrike WEB JSON (including poetry lines)
base_url = "https://raw.githubusercontent.com/TehShrike/world-english-bible/refs/heads/master/json/"
books = ["Matthew", "Mark", "Luke", "John"]

verse_map = defaultdict(lambda: defaultdict(dict))

for book in books:
    url = f"{base_url}{book.lower()}.json"
    print(f"Downloading {url} ...")
    r = requests.get(url)
    book_data = r.json()

    temp_verses = defaultdict(lambda: defaultdict(list))

    for entry in book_data:
        if entry.get("type") in ["paragraph text", "verse", "paragraph end", "line text"]:
            if "chapterNumber" not in entry or "verseNumber" not in entry:
                continue
            c = int(entry["chapterNumber"])
            v = int(entry["verseNumber"])
            value = entry["value"].strip()
            if value:  # skip completely blank lines
                temp_verses[c][v].append(value)

    # Merge multiple lines for each verse
    for c, verses in temp_verses.items():
        for v, parts in verses.items():
            verse_map[book][c][v] = " ".join(parts).strip()

print("✅ Finished loading WEB Bible locally.")

# ✅ Build Jefferson Bible text
output_lines = []

for ref in jeff_refs:
    match = re.match(r"(\w+) (\d+):(\d+)(?:-(\d+))?", ref)
    if not match:
        continue
    raw_book = match.group(1)
    book = BOOK_MAP.get(raw_book, raw_book).capitalize()
    chap = int(match.group(2))
    start = int(match.group(3))
    end = int(match.group(4)) if match.group(4) else start

    for vnum in range(start, end + 1):
        text = verse_map[book].get(chap, {}).get(vnum)
        if text and text.strip():
            output_lines.append(text)

# ✅ Save clean output to Drive
with open(output_path, "w", encoding="utf-8") as f:
    f.write("\n".join(output_lines))

print(f"✅ Jefferson Bible (WEB) saved to {output_path} with {len(output_lines)} lines.")

import re

input_path = "/content/drive/MyDrive/bens_bible/jefferson_bible_web_offline.txt"
output_path = "/content/drive/MyDrive/bens_bible/jefferson_bible_latex.tex"

# Simple LaTeX escaper
def escape_latex(text):
    specials = {
        "&": r"\&",
        "%": r"\%",
        "$": r"\$",
        "#": r"\#",
        "_": r"\_",
        "{": r"\{",
        "}": r"\}",
        "~": r"\textasciitilde{}",
        "^": r"\textasciicircum{}",
        "\\": r"\textbackslash{}"
    }
    for k, v in specials.items():
        text = text.replace(k, v)
    return text

lines = []
with open(input_path, "r", encoding="utf-8") as f:
    verses = [escape_latex(line.strip()) for line in f if line.strip()]

page_counter = 1
new_page = True

for i, verse in enumerate(verses):
    if new_page:
        lines.append("\\chapterornament")
        lines.append(f"\\section*{{Page {page_counter}}}\n")
        # Add drop cap for first letter
        first_letter = verse[0]
        rest = verse[1:]
        lines.append(f"\\lettrine{{{first_letter}}}{{{rest}}}\n")
        new_page = False
    else:
        lines.append(verse + "\n")

    # Example rule: every ~20 verses = new page (tweak later to Jefferson's actual pages)
    if (i + 1) % 20 == 0:
        page_counter += 1
        new_page = True
        lines.append("\n")

# Write to file
with open(output_path, "w", encoding="utf-8") as f:
    f.write("\n".join(lines))

print(f"✅ LaTeX file saved to {output_path}")